
---
layout: page
title: ""
permalink: /chapter7.html
---

# Chapter 7 Notes

- [Back To HomePage](index.md)

## User Research

I think user research is basically about understanding who your users are and how they actually behave, especially early on in a project. It helps me prioritize which users matter most, understand their frustrations, and see how well the current product is (or isn’t) working.

## Basic Steps of User Research

I see user research as a process you can break into clear steps instead of something overwhelming. I define my users, plan and run the research, share findings, and use what I learn to shape better, user-focused product ideas.

## Define Your User Groups

I think defining user groups upfront helps me avoid guessing and gives my research some direction, even if those assumptions aren’t validated yet. These provisional user models help me focus on the right people while staying open to changing them once real research comes in.

## Create a List of Attributes

I start by gathering everything the organization already knows about users, like past research, analytics, and customer feedback. Then I work with stakeholders to list common attributes—like goals, experience, or demographics—that actually affect how users interact with the product.

## Prioritize and Define

I focus on the attributes that have the biggest impact on user behavior instead of trying to track everything at once. Prioritizing these helps me segment users in a way that actually supports research, design decisions, and recruiting the right participants.

## Can You Design from Provisional User Models Alone?

I think designing only from assumptions is risky, but it’s still better than having no model at all when user access is limited. The key is being honest that these models are guesses and committing to refining them with real research later.

## Plan Your Research

I see research planning as making sure everyone agrees on what we’re trying to learn before we spend time or money. By setting clear goals, objectives, and hypotheses, I can choose the right research methods and actually get useful results.

## Qualitative Research vs. Quantitative Research

I think quantitative research is all about numbers and confidence, like using surveys or analytics to see patterns across a big group. Qualitative research is more about context and understanding why users do things, which is why combining both gives the clearest picture.

## How Bias Creeps In (Cognitive Bias)

I see cognitive bias as something that can quietly mess with research if I’m not careful, especially when I start favoring answers I expected. Being aware of biases like confirmation bias or social desirability bias helps me stay more objective and trust the results.

## Product Analytics

I think product analytics are super useful when you already have users, because they show what people are actually doing in the product. Metrics like bounce rate or retention help me spot problem areas before I even talk to users.

## Event Tracking and Funnels

I see events as specific actions users take, and funnels as a way to track where users drop off during a process. If I notice a big drop at one step, that’s usually a sign that something needs research or a design change.

## Planning Ahead for Analytics

I think adding event tracking early is important, even if I’m not totally sure how I’ll use the data yet. The earlier it’s set up, the sooner I can get meaningful insights once users start interacting with the feature.

## Working with Analytics Across Teams

I see analytics as a team effort, since I might need help from product managers, analysts, or developers to get the data I want. Asking clear questions upfront makes it easier to figure out what data is actually useful.

## Sessions and User Behavior

I think looking at user behavior within a single session helps me understand how people actually move through the product. Defining what counts as a session matters because it changes how I interpret the data.

## Choose Your Research Method(s)

I see this step as deciding what mix of research will give me the best insight for the time and resources I have. Even without analytics, there are plenty of research methods that can still build a solid understanding of users.

## Which Methods Should I Use?

I think different research methods work better depending on what I’m trying to learn, like behavior versus opinions. Having a range of qualitative and quantitative options gives me flexibility.

## Common User-Research Methods (Table Overview)

I see this table as a quick reference that shows what each research method is best for and what challenges come with it. It helps me pick methods that actually fit the project instead of defaulting to whatever sounds easiest.

## How Many Research Activities Can I Include?

I think the number of research activities really depends on time, budget, and how comfortable the team is with research. If leadership supports it, I have way more freedom to test, iterate, and validate designs.

## Considerations When Planning Research

I see research planning as balancing risk, goals, users, and logistics all at once. Thinking through these details upfront saves me from wasting time or running research that doesn’t answer the right questions.

## Phasing Research Across the Project

I think a smart approach is to do research early to understand users, then do another round later to validate designs. This way, I’m not guessing at the start or shipping something untested at the end.

## User Interviews

I think user interviews are basically structured conversations where I talk to real users to learn their attitudes, goals, and pain points. They’re great for understanding preferences, but if I want to know how people actually perform on the site, I should watch them use it or pull analytics.

## User Interviews – The Basic Process

I create a solid question list, keep things consistent if multiple people are interviewing, and use one organized place to log everything so I can spot trends later. I also decide if I want super structured interviews for cleaner results or semi-structured ones so I can follow interesting answers and probe deeper.

## Interviewing Tips

I think the biggest thing is asking neutral, open-ended questions that focus on what people actually did, not what they think they might do someday. I avoid leading questions, do a test run to fix the flow, and record (with consent) so I don’t miss important details.

## Contextual Inquiry

I see contextual inquiry as interviews + real-life observation, where I go to the user’s environment and watch how they work. It’s crazy useful because I learn about their tools, space, interruptions, and habits—stuff that totally affects what design will actually work.

## Contextual Inquiry – The Basic Process

I start with a short intro and consent stuff, ask a few high-level questions, then switch into observation mode. Depending on time, I either do active observation (they explain everything like I’m learning) or passive observation (I stay quiet so behavior stays natural).

## Focus Groups

I think focus groups are good when I want a bunch of user perspectives at once, especially for stories, attitudes, and idea sparks. But I wouldn’t use them for usability testing, because group dynamics can influence what people say, and most users don’t use products in a group.

## Focus Groups – The Basic Process

I start with easy warm-up questions, manage time blocks so we don’t get stuck on one topic, and keep the group around 6–8 people in person (or smaller if remote). As moderator I’m basically controlling the flow, making sure everyone talks, and using body language cues to keep one person from taking over.

## Card Sorting

I think card sorting is a simple way to figure out how users naturally group and label content, especially for websites or intranets with a ton of info. It helps me build a sitemap or navigation that matches how users think, not just how departments are organized.

## Card Sorting – The Basic Process

I pick like 40–60 clear items, avoid too much insider jargon, and let participants group cards in a way that makes sense to them and name the groups. I do a test run to check timing, then analyze patterns and disagreements to spot where the info structure is confusing.

## Variations on the Card Sort

I see open sorts as best when I’m creating a new structure, because users get to name the categories themselves. Closed sorts are better when I already have categories and I’m validating them, and group sorts are good when I want to hear people debate and explain their thinking together.

## Surveys

I think surveys are basically a way to ask a lot of people the same clear questions so I can get patterns and numbers out of it. They’re best when I want to say results confidently like “X% of users said ___,” but I can still learn some attitude stuff too.

## Surveys That Work

I’ve seen how surveys can be straight-up useless if the questions are trash or they’re sent to the wrong people. Having solid survey design skills is important because it’s one of those tools I can always pull out, especially for satisfaction and validating user models.

## Surveys – The Basic Process

I don’t ask “future guessing” questions like “would you use this,” because people lie without meaning to. I stick to mostly closed-ended questions (multiple choice / scales) so results are easier to analyze and compare.

## Survey Tips

I think the biggest thing is knowing who I’m targeting, how I’m distributing it, and how long people will actually tolerate before they quit. I also need a clear stopping point (deadline or response count) and a plan for how I’m collecting + analyzing the data.

## Survey Tools

I’d use tools like Google Forms, SurveyMonkey, Typeform, or Jotform, depending on how fancy I need it and what kind of analysis I want. If I’m trying to catch feedback right after a user does something, embedding a quick in-product survey can be clutch.

## Usability Testing

I think usability testing is where I actually watch people try to complete real tasks on the site or prototype, so I can spot what’s confusing or broken. It’s useful both for improving an existing product and for testing designs in rounds, so I can refine them before dev.

## A/B Testing

I see A/B testing as a way to compare two designs and see which one performs better, usually on a live site with real users. It works best when I keep variables limited so I can tell why one version won, and it can be used qualitatively too when comparing concepts.

## Longitudinal Studies

I think longitudinal research is basically staying in touch over time, because users and products change, and I can’t assume one study is enough forever. Running recurring surveys like CSAT or doing diary-style studies helps me track shifts in satisfaction, needs, or real-life context.

## Form and Share Findings

I see this stage as taking everything I gathered and turning it into something actually usable for the team, not just a pile of notes. Quant data often comes with built-in charts, but qual data needs synthesis so I can pull out real patterns and themes.

## A Quick Guide to Affinity Diagramming

I think affinity diagramming is basically clustering quotes and observations (like sticky notes) until patterns start to show up naturally. It works best as a team activity because the discussions about “where does this go?” help reveal the real themes.

## Sharing Your Findings

I think the main goal is making findings easy to digest, because nobody wants to read a giant report front to back. A slide deck with visuals + user quotes (and maybe short clips) makes it way more likely stakeholders actually understand and act on the insights.

## Ask the Experts: Katie Swindler

I agree with the idea that qual tells me the “why” and quant tells me “how many,” and both together hits harder when presenting. Exec/business people usually want numbers, while designers/dev teams need the human context to solve the problem right.

## After the Research

I think after research, I have to revisit my assumptions and basically rebuild my user groups based on what I learned, not what I guessed at the start. Then I can update my user model, fill any gaps, and start shaping personas and better solutions based on real needs.
